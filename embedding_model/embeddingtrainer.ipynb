{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0948d168-bc6d-49f0-a0a8-46ffef674a9c",
   "metadata": {},
   "source": [
    "# Embedding Trainer\n",
    "---\n",
    "Main script to train our various embedding models. What we'll do is import our 'Embedding Model' objects that we'll define in other files - and this code will be the training loop and will save the results to various folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5d43-dfc7-4007-9d54-8527bbf69b22",
   "metadata": {},
   "source": [
    "## Create our Dataloader and Tokenizer\n",
    "---\n",
    "We already defined these and trained the tokenizer in the other files. So, let's go ahead and instantiate these as a first step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84fc05-e0dc-4820-b6d5-7593b3569bda",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce4ce0c-327e-4491-a5d2-97dae3584ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First - need to import sys and os and nav to our project_root\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Now import our dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataloader.dataloader import MyDataLoader\n",
    "from tokenizer.tokenizer import MyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49e9ebe-1710-4b4b-9828-c79e96dd34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18bf2d-67c0-4610-bee2-c956cb56b126",
   "metadata": {},
   "source": [
    "### Instantiate our Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b78d90c-3957-4114-90e7-8bf6a60c19c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "Number of chars: 1832\n",
      "============================================================\n",
      "'''The Act Declaring the Independence of Ukraine''' was proclaimed by the Verkhovna Rada of the Ukra\n",
      "\n",
      "\n",
      "Test Data:\n",
      "Number of chars: 1369\n",
      "============================================================\n",
      "eries in the world of animal psychology which amaze us. Presently the spell was broken and without w\n"
     ]
    }
   ],
   "source": [
    "dl = MyDataLoader(\n",
    "    promptuser=False, \n",
    "    batch_size=1, \n",
    "    shuffle=True)    \n",
    "# By setting promptuser=False, we just use the 'enwiki_articles_20240320_mini' dataset (50MB)\n",
    "\n",
    "train_dataloader = dl.get_train_dataloader()\n",
    "test_dataloader = dl.get_test_dataloader()\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    sample_data = batch[0][0]\n",
    "    break\n",
    "for batch in test_dataloader:\n",
    "    sample_testdata = batch[0][0]\n",
    "    break\n",
    "\n",
    "\n",
    "print(f\"Train Data:\\nNumber of chars: {len(sample_data)}\\n{'='*60}\")\n",
    "print(sample_data[:100])\n",
    "print(f\"\\n\\nTest Data:\\nNumber of chars: {len(sample_testdata)}\\n{'='*60}\")\n",
    "print(sample_testdata[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d56a8-872e-45bc-93e6-cda4428f947a",
   "metadata": {},
   "source": [
    "### Instantiate our Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f352301-58ec-4c6a-ba92-101ea383444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1053, 828, 2628, 7584, 1890, 6, 11305, 16, 296, 16214, 95, 240, 934, 121, 10685, 111, 6, 5672, 16214, 16198, 4040, 3647, 227, 4217, 16, 6, 296, 16214, 95]\n",
      "------------------------------------------------------------\n",
      "[\"▁'''\", 'The', '▁Act', '▁Decl', 'aring', '▁the', '▁Independence', '▁of', '▁U', 'k', 'ra', 'ine', \"'''\", '▁was', '▁proclaimed', '▁by', '▁the', '▁Ver', 'k', 'h', 'ov', 'na', '▁R', 'ada', '▁of', '▁the', '▁U', 'k', 'ra']\n",
      "------------------------------------------------------------\n",
      "'''The Act Declaring the Independence of Ukraine''' was proclaimed by the Verkhovna Rada of the Ukra\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MyTokenizer()\n",
    "tk_vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "# Ensure our tokenizer is running properly\n",
    "chars_to_print = 100\n",
    "print(tokenizer.encode_as_ids(sample_data[:chars_to_print]))\n",
    "print(f\"{'-'*60}\")\n",
    "print(tokenizer.encode_as_pieces(sample_data[:chars_to_print]))\n",
    "print(f\"{'-'*60}\")\n",
    "print(tokenizer.decode(tokenizer.encode_as_ids(sample_data[:chars_to_print])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0484a7-8dbf-4e9f-a809-4f3936f30949",
   "metadata": {},
   "source": [
    "## Define our Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d5caaa-7fa2-4591-a07e-7d469f9c799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "------------------------------------------------------------\n",
      "tensor([[   37,  5420, 16269,   338,     6,    74,    43,  1709],\n",
      "        [  587, 16210,    32,   803, 16210,    98,    32,  1252],\n",
      "        [16197,   101,   324,  9813,   800,   545,  5706,   254],\n",
      "        [16197,  6445,     6,   445,   191,   665,   310,   637],\n",
      "        [12178, 16213,    57,   369,    16,   110,  2058,    74],\n",
      "        [ 5842,   445,    74,    32,  2172, 16210,  2212,  7577],\n",
      "        [ 1469, 13047, 16213,   151,    26,   121,   576, 14544],\n",
      "        [  110,   406,    65,   162, 16210,    21,   298,    63]],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "tensor([ 907,  129,  525,  121,  301, 8995, 5420, 3483], device='cuda:0',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def _yield_CBOW_batch(text, n_window, batch_size=8, util_rate=0.5, spec_iter=None, vocab_size=tk_vocab_size, device=device, tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "        Generator function that takes in text and returns a number of batches for each dataset based on the utilization rate specified. To be used in a CBOW model.\n",
    "\n",
    "        Inputs:\n",
    "            text:       (string) The text provided by the dataloader\n",
    "            n_window:   (int) Size of our context window for the CBOW model. I.e., if n_window=4, then we will use the left 4 words and right 4 words to predict our target word\n",
    "            batch_size: (int) Number of samples to return in each batch\n",
    "            util_rate:  (float) Value from (0, 1] that specifies the % of possible batches that are generated before moving to next sample\n",
    "            spec_iter:  (int) If set to none, we use util rate to determine num batches from this data. If set to an int, we use that number.\n",
    "            vocab_size: (int) size of our tokenizer vocabulary\n",
    "            device:     Pytorch device (e.g., cuda / cpu)\n",
    "            tokenizer:  Our defined tokenizer (above). encode_as_ids(text) returns a 1-D python list of tokens\n",
    "\n",
    "        Yields (generator function) batches of data in the form of GPU-mounted pytorch tensors until util_rate is tripped.\n",
    "    \"\"\"\n",
    "    # Tokenize our data and determine number of batches we'll use\n",
    "    tokens = torch.tensor(tokenizer.encode_as_ids(text), dtype=torch.int, device=device)\n",
    "    len_tokens = len(tokens)\n",
    "    num_possible_pairs = len_tokens - (2 * n_window)\n",
    "    num_batches = int((num_possible_pairs * util_rate) // batch_size) if spec_iter==None else min(spec_iter, int(num_possible_pairs // batch_size))\n",
    "\n",
    "    # Get random permutation of the possible 'center indices' --> these become our targets and surrounding 'n_window' size is our context\n",
    "    center_indices = torch.arange(n_window, len_tokens - n_window, device=device).int()\n",
    "    center_indices = center_indices[torch.randperm(center_indices.size(0))][:num_batches*batch_size]\n",
    "\n",
    "    # Generate # of batches for this dataset\n",
    "    for i in range(num_batches):\n",
    "        batch_center_indices = center_indices[i*batch_size:(i+1)*batch_size]\n",
    "        context_indices_list = []\n",
    "        target_indices_list = []\n",
    "        \n",
    "        for center_idx in batch_center_indices:\n",
    "            # Create a context window around the center word\n",
    "            context_window = tokens[(center_idx - n_window):(center_idx + n_window + 1)]\n",
    "            context_indices = torch.cat((context_window[:n_window], context_window[n_window+1:]))\n",
    "            target_index = tokens[center_idx]\n",
    "            \n",
    "            context_indices_list.append(context_indices)\n",
    "            target_indices_list.append(target_index)\n",
    "        \n",
    "        # Stack lists to create batch tensors\n",
    "        context_tensor = torch.stack(context_indices_list).to(device)\n",
    "        target_tensor = torch.stack(target_indices_list).to(device)\n",
    "        \n",
    "        yield context_tensor, target_tensor\n",
    "\n",
    "for batch, (context, target) in enumerate(_yield_CBOW_batch(sample_data, n_window=4)):\n",
    "    print(f\"Batch {batch+1}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(context)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8baec6a3-9c0b-4b6f-852d-e6c91d9b1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next - let's keep track of our loss data\n",
    "def _estimate_loss(model, n_window, batching_fn, train_dl, test_dl, n_samples=10, iters_per_sample=10, device=device):\n",
    "    \"\"\"\n",
    "        Function to estimate our loss (train and test) that we can call\n",
    "\n",
    "        Inputs:\n",
    "            model:             Pytorch sequential model\n",
    "            n_window:          (int) Specify size of window to test over (for our CBOW / Skipgram models)\n",
    "            batching_fn:       Function that returns our data as (context, targets)\n",
    "            train_dl:          Pytorch dataloader for train data\n",
    "            test_dl:           Pytorch dataloader for test data\n",
    "            n_samples:         (int) Specify number of iterations to compute loss over\n",
    "            iters_per_sample:  (int) Specify number of iterations per sample to compute loss over\n",
    "            device:            Pytorch device (cuda / cpu)\n",
    "\n",
    "        Returns the mean train loss and the test loss over n_iters samples\n",
    "    \"\"\"\n",
    "    train_loss = torch.zeros(n_samples*iters_per_sample, device=device)\n",
    "    test_loss = torch.zeros(n_samples*iters_per_sample, device=device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(train_dl):\n",
    "            for (context, targets) in batching_fn(sample[0][0], n_window, spec_iter=iters_per_sample):\n",
    "                loss = model(context, targets)\n",
    "                train_loss[i-1] += loss\n",
    "            if i == n_samples:\n",
    "                break\n",
    "        for i, sample in enumerate(test_dl):\n",
    "            for (context, targets) in batching_fn(sample[0][0], n_window, spec_iter=iters_per_sample):\n",
    "                loss = model(context, targets)\n",
    "                test_loss[i-1] += loss\n",
    "            if i == n_samples:\n",
    "                break\n",
    "\n",
    "    model.train()\n",
    "    return train_loss.mean(), test_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b79f7-2cce-4228-957d-5e02fd728ced",
   "metadata": {},
   "source": [
    "## Import and Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "497fba5e-bae1-4cf3-acdc-ce5968c3143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Bag of Words model for training embeddings as specified in Word2Vec (https://arxiv.org/pdf/1301.3781.pdf)\n",
    "class CBOW_NegativeSampling(nn.Module):\n",
    "    def __init__(self, embed_dim, tokenizer, effic_strat=None, vocab_size=tk_vocab_size, device=device):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            embed_dim:   (int) number of dimensions for our embeddings\n",
    "            effic_strat: (str) either 'neg-sample' or 'hier-softmax' - used to define which strategy for efficient computation to use\n",
    "            vocab_size:  (int) the size of the vocabulary\n",
    "            device:      Pytorch device (cuda / cpu)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embed_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_frequencies = tokenizer.get_frequency_tensor().to(device)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim).to(device)\n",
    "        \n",
    "        self.initialize_embeddings()\n",
    "\n",
    "    def initialize_embeddings(self):\n",
    "        \"\"\" Initializes the embedding weights to a normal distribution with mean 0 and a specified variance \"\"\"\n",
    "        nn.init.normal_(self.embeddings.weight, mean=0.0, std=1)\n",
    "\n",
    "    def forward(self, context_indices, positive_indices, num_negative_samples=5):\n",
    "        \"\"\"\n",
    "            Performs a forward pass with negative sampling.\n",
    "            \n",
    "            Parameters:\n",
    "            - context_indices: Indices of the context words [B, Context_size].\n",
    "            - positive_indices: Indices of the target (positive) words [B, 1].\n",
    "            - num_negative_samples: Number of negative samples per positive sample.\n",
    "        \"\"\"\n",
    "        batch_size = context_indices.size(0)\n",
    "        context_embeds = self.embeddings(context_indices).mean(dim=1, keepdims=True)  # [B, context_size, embed_dim] --> [B x 1 x embed_dim]\n",
    "    \n",
    "        # Embedding lookup for positive samples\n",
    "        positive_embeds = self.embeddings(positive_indices).unsqueeze(-1)  # [B, embed_dim, 1]\n",
    "    \n",
    "        # Generating negative samples\n",
    "        negative_indices = torch.multinomial(self.token_frequencies, num_samples=batch_size*num_negative_samples, replacement=True).reshape(batch_size, num_negative_samples)\n",
    "        negative_embeds = self.embeddings(negative_indices).transpose(1,2)  # [B, embed_dim, num_negative_samples]\n",
    "    \n",
    "        # Compute logits\n",
    "        positive_logits = torch.bmm(context_embeds, positive_embeds).squeeze()      # [B x 1 x embed_dim] @ [B, embed_dim, 1] -> [B, 1, 1] -> [B]\n",
    "        negative_logits = torch.bmm(context_embeds, negative_embeds).squeeze()      # [B, num_negative_samples]\n",
    "    \n",
    "        # Labels: 1s for positive, 0s for negative\n",
    "        positive_labels = torch.ones_like(positive_logits)\n",
    "        negative_labels = torch.zeros_like(negative_logits)\n",
    "    \n",
    "        # Loss: binary cross-entropy with logits\n",
    "        positive_loss = F.binary_cross_entropy_with_logits(positive_logits, positive_labels)\n",
    "        negative_loss = F.binary_cross_entropy_with_logits(negative_logits, negative_labels)\n",
    "        loss = positive_loss + negative_loss.mean()\n",
    "        return loss\n",
    "\n",
    "    def find_closest_embeddings(self, input_embedding, n=5):\n",
    "        \"\"\"\n",
    "            Find the n embeddings in the model that have the largest cosine similarity\n",
    "            to the given input_embedding.\n",
    "    \n",
    "            Inputs:\n",
    "                input_embedding (Tensor): The input embedding vector.\n",
    "                n (int): The number of closest embeddings to return.\n",
    "    \n",
    "            Returns a tensor of indices of the n closest embeddings.\n",
    "        \"\"\"\n",
    "        input_embedding_norm = input_embedding / input_embedding.norm()                    # [1 x emb_dim]\n",
    "        all_embeddings = self.embeddings.weight\n",
    "        all_embeddings_norm = all_embeddings / all_embeddings.norm(dim=1, keepdim=True)    # [vocab_size x emb_dim]\n",
    "        similarities = F.cosine_similarity(input_embedding_norm, all_embeddings_norm, dim=1)\n",
    "        values, indices = torch.topk(similarities, n)\n",
    "        return indices\n",
    "\n",
    "    def get_embedding(self, index):\n",
    "        \"\"\" Retrieve the vector embedding corresponding to a given index Returns a tensor of the embedding vector \"\"\"\n",
    "        return self.embeddings.weight[index]\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        \"\"\" Save the model weights to a file \"\"\"\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        \"\"\" Load the model weights from a file. Ex. 'trained_models/mymodel.pth' \"\"\"\n",
    "        self.load_state_dict(torch.load(filename, map_location=self.device))\n",
    "        print(f\"Model weights loaded from {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a5f9a-284e-4c90-a2a2-9cf3db496ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Bag of Words model for training embeddings as specified in Word2Vec (https://arxiv.org/pdf/1301.3781.pdf)\n",
    "class CBOW_HierarchalSoftmax(nn.Module):\n",
    "    def __init__(self, embed_dim, tokenizer, effic_strat=None, vocab_size=tk_vocab_size, device=device):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            embed_dim:   (int) number of dimensions for our embeddings\n",
    "            effic_strat: (str) either 'neg-sample' or 'hier-softmax' - used to define which strategy for efficient computation to use\n",
    "            vocab_size:  (int) the size of the vocabulary\n",
    "            device:      Pytorch device (cuda / cpu)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embed_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_frequencies = tokenizer.get_frequency_tensor().to(device)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim).to(device)\n",
    "        \n",
    "        self.initialize_embeddings()\n",
    "\n",
    "    def initialize_embeddings(self):\n",
    "        \"\"\" Initializes the embedding weights to a normal distribution with mean 0 and a specified variance \"\"\"\n",
    "        nn.init.normal_(self.embeddings.weight, mean=0.0, std=1)\n",
    "\n",
    "    def forward(self, context_indices, positive_indices, num_negative_samples=5):\n",
    "        \"\"\"\n",
    "            Performs a forward pass with negative sampling.\n",
    "            \n",
    "            Parameters:\n",
    "            - context_indices: Indices of the context words [B, Context_size].\n",
    "            - positive_indices: Indices of the target (positive) words [B, 1].\n",
    "            - num_negative_samples: Number of negative samples per positive sample.\n",
    "        \"\"\"\n",
    "        batch_size = context_indices.size(0)\n",
    "        context_embeds = self.embeddings(context_indices).mean(dim=1, keepdims=True)  # [B, context_size, embed_dim] --> [B x 1 x embed_dim]\n",
    "    \n",
    "        # Embedding lookup for positive samples\n",
    "        positive_embeds = self.embeddings(positive_indices).unsqueeze(-1)  # [B, embed_dim, 1]\n",
    "    \n",
    "        # Generating negative samples\n",
    "        negative_indices = torch.multinomial(self.token_frequencies, num_samples=batch_size*num_negative_samples, replacement=True).reshape(batch_size, num_negative_samples)\n",
    "        negative_embeds = self.embeddings(negative_indices).transpose(1,2)  # [B, embed_dim, num_negative_samples]\n",
    "    \n",
    "        # Compute logits\n",
    "        positive_logits = torch.bmm(context_embeds, positive_embeds).squeeze()      # [B x 1 x embed_dim] @ [B, embed_dim, 1] -> [B, 1, 1] -> [B]\n",
    "        negative_logits = torch.bmm(context_embeds, negative_embeds).squeeze()      # [B, num_negative_samples]\n",
    "    \n",
    "        # Labels: 1s for positive, 0s for negative\n",
    "        positive_labels = torch.ones_like(positive_logits)\n",
    "        negative_labels = torch.zeros_like(negative_logits)\n",
    "    \n",
    "        # Loss: binary cross-entropy with logits\n",
    "        positive_loss = F.binary_cross_entropy_with_logits(positive_logits, positive_labels)\n",
    "        negative_loss = F.binary_cross_entropy_with_logits(negative_logits, negative_labels)\n",
    "        loss = positive_loss + negative_loss.mean()\n",
    "        return loss\n",
    "\n",
    "    def find_closest_embeddings(self, input_embedding, n=5):\n",
    "        \"\"\"\n",
    "            Find the n embeddings in the model that have the largest cosine similarity\n",
    "            to the given input_embedding.\n",
    "    \n",
    "            Inputs:\n",
    "                input_embedding (Tensor): The input embedding vector.\n",
    "                n (int): The number of closest embeddings to return.\n",
    "    \n",
    "            Returns a tensor of indices of the n closest embeddings.\n",
    "        \"\"\"\n",
    "        input_embedding_norm = input_embedding / input_embedding.norm()                    # [1 x emb_dim]\n",
    "        all_embeddings = self.embeddings.weight\n",
    "        all_embeddings_norm = all_embeddings / all_embeddings.norm(dim=1, keepdim=True)    # [vocab_size x emb_dim]\n",
    "        similarities = F.cosine_similarity(input_embedding_norm, all_embeddings_norm, dim=1)\n",
    "        values, indices = torch.topk(similarities, n)\n",
    "        return indices\n",
    "\n",
    "    def get_embedding(self, index):\n",
    "        \"\"\" Retrieve the vector embedding corresponding to a given index Returns a tensor of the embedding vector \"\"\"\n",
    "        return self.embeddings.weight[index]\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        \"\"\" Save the model weights to a file \"\"\"\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        \"\"\" Load the model weights from a file. Ex. 'trained_models/mymodel.pth' \"\"\"\n",
    "        self.load_state_dict(torch.load(filename, map_location=self.device))\n",
    "        print(f\"Model weights loaded from {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5557ee7-421f-48fa-bca3-cc404503938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple training loop\n",
    "def train_model(embedding_model, train_dl, test_dl, tokenizer, device, embed_dim, learning_rate, epochs, max_iters, print_freq=2000, saveweights=True):\n",
    "    \"\"\"\n",
    "    Main training loop for the model specified in 'embedding_model'.\n",
    "    \n",
    "    Parameters:\n",
    "    - embedding_model: The key to the embedding model configuration.\n",
    "    - train_dl: Training DataLoader.\n",
    "    - test_dl: Testing DataLoader.\n",
    "    - tokenizer: Tokenizer used for encoding text.\n",
    "    - device: The device (cuda/cpu) on which to train the model.\n",
    "    - epochs: Number of epochs to train for.\n",
    "    - saveweights: Whether to save the model weights.\n",
    "    - embed_dim: Dimensionality of the embeddings.\n",
    "    - learning_rate: Learning rate for the optimizer.\n",
    "    \"\"\"\n",
    "    modelclass = emb_model[embedding_model][\"modelclass\"]\n",
    "    n_window = emb_model[embedding_model][\"n_window\"]\n",
    "    batching_fn = emb_model[embedding_model][\"batching_fn\"]\n",
    "    \n",
    "    model = modelclass(embed_dim=embed_dim, \n",
    "                       tokenizer=tokenizer,\n",
    "                       device=device)\n",
    "    model.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"{(sum(p.numel() for p in model.parameters())/1e6):.3f}M parameters\")\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = torch.zeros(int(max_iters//print_freq), 3, device=device)\n",
    "    iter = 0\n",
    "\n",
    "    def save_model_and_losses():\n",
    "        datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        file_prefix = f\"{embedding_model}-{tokenizer.get_vocab_size()//1000}k-{datetime_str}\"\n",
    "        weights_path = os.path.join('trained_models', file_prefix + '.pth')\n",
    "        model.save_weights(weights_path)\n",
    "        print(f\"Model weights saved to {weights_path}\")\n",
    "        \n",
    "        losses_df = pd.DataFrame(losses.cpu().numpy(), columns=['Iteration', 'Train Loss', 'Test Loss'])\n",
    "        csv_path = os.path.join('loss_results', file_prefix + '.csv')\n",
    "        losses_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Loss data saved to {csv_path}\")\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for sample in train_dl:\n",
    "            for (context, targets) in batching_fn(sample[0][0], n_window):\n",
    "                iter += 1\n",
    "                loss = model(context, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if iter % print_freq == 0:\n",
    "                    train_loss, test_loss = _estimate_loss(model, n_window, batching_fn, train_dl, test_dl, n_samples=5, iters_per_sample=10, device=device)\n",
    "                    print(f\"{iter}/{int(max_iters)}: Train loss = {train_loss:.3f}; Test loss = {test_loss:.3f}\")\n",
    "                    \n",
    "                    print_idx = iter//print_freq - 1\n",
    "                    losses[print_idx] = torch.tensor([iter, train_loss, test_loss], device=device)\n",
    "\n",
    "                if iter % 5e5 == 0:\n",
    "                    save_model_and_losses()\n",
    "                \n",
    "                if iter >= max_iters:\n",
    "                    break    \n",
    "            if iter >= max_iters:\n",
    "                break\n",
    "        if iter >= max_iters:\n",
    "            break\n",
    "    \n",
    "    # Save model and losses\n",
    "    save_model_and_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b111a58-54b5-4b26-9b94-2c85302c8440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "8.389M parameters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Training our model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m train_model(embedding_model\u001b[38;5;241m=\u001b[39membedding_model, \n\u001b[0;32m     17\u001b[0m                    train_dl\u001b[38;5;241m=\u001b[39mtrain_dataloader, \n\u001b[0;32m     18\u001b[0m                    test_dl\u001b[38;5;241m=\u001b[39mtest_dataloader, \n\u001b[0;32m     19\u001b[0m                    tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[0;32m     20\u001b[0m                    device\u001b[38;5;241m=\u001b[39mdevice, \n\u001b[0;32m     21\u001b[0m                    embed_dim\u001b[38;5;241m=\u001b[39membed_dim, \n\u001b[0;32m     22\u001b[0m                    learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, \n\u001b[0;32m     23\u001b[0m                    epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     24\u001b[0m                    max_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e6\u001b[39m,\n\u001b[0;32m     25\u001b[0m                    print_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[66], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(embedding_model, train_dl, test_dl, tokenizer, device, embed_dim, learning_rate, epochs, max_iters, print_freq, saveweights)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m train_dl:\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (context, targets) \u001b[38;5;129;01min\u001b[39;00m batching_fn(sample[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], n_window):\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     48\u001b[0m             loss \u001b[38;5;241m=\u001b[39m model(context, targets)\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36m_yield_CBOW_batch\u001b[1;34m(text, n_window, batch_size, util_rate, spec_iter, vocab_size, device, tokenizer)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m center_idx \u001b[38;5;129;01min\u001b[39;00m batch_center_indices:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Create a context window around the center word\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     context_window \u001b[38;5;241m=\u001b[39m tokens[(center_idx \u001b[38;5;241m-\u001b[39m n_window):(center_idx \u001b[38;5;241m+\u001b[39m n_window \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m---> 36\u001b[0m     context_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((context_window[:n_window], context_window[n_window\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]))\n\u001b[0;32m     37\u001b[0m     target_index \u001b[38;5;241m=\u001b[39m tokens[center_idx]\n\u001b[0;32m     39\u001b[0m     context_indices_list\u001b[38;5;241m.\u001b[39mappend(context_indices)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining our different embedding models\n",
    "emb_model = {\n",
    "    \"CBOW-5-NS\": {\"modelclass\": CBOW_NegativeSampling, \"batching_fn\": _yield_CBOW_batch, \"n_window\": 5},\n",
    "    \"CBOW-3-NS\": {\"modelclass\": CBOW_NegativeSampling, \"batching_fn\": _yield_CBOW_batch, \"n_window\": 3},\n",
    "    \"Ngram-5-NS\": {\"modelclass\": \"TBD\", \"batching_fn\": \"TBD\", \"n_window\": 5},\n",
    "    \"Ngram-5-HS\": {\"modelclass\": \"TBD\", \"batching_fn\": \"TBD\", \"n_window\": 5},\n",
    " }\n",
    "\n",
    "# Training specific hyperparams\n",
    "embedding_model = \"CBOW-5-NS\"\n",
    "learning_rate = 3e-4\n",
    "embed_dim = 512\n",
    "epochs = 50\n",
    "\n",
    "# Training our model\n",
    "loss = train_model(embedding_model=embedding_model, \n",
    "                   train_dl=train_dataloader, \n",
    "                   test_dl=test_dataloader, \n",
    "                   tokenizer=tokenizer, \n",
    "                   device=device, \n",
    "                   embed_dim=embed_dim, \n",
    "                   learning_rate=learning_rate, \n",
    "                   epochs=epochs,\n",
    "                   max_iters=2e6,\n",
    "                   print_freq=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea87b09-1c0e-4ef0-ad28-8d2a4c1693c7",
   "metadata": {},
   "source": [
    "## Plotting Loss and Testing our Trained Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06c73c7a-bb0b-4d13-92fb-d918990de6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15b5bfa7-b96d-438f-9f0a-139ec545f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(filename):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(os.path.join('loss_results', filename))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['Iteration'], df['Train Loss'], color='blue', label='Train Loss', s=10)  # Adjusted size here\n",
    "    plt.scatter(df['Iteration'], df['Test Loss'], color='orange', label='Test Loss', s=10)  # And here\n",
    "    plt.title('Training and Test Loss Over Time')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ac52176-16e7-4608-992c-59489e43c75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_loss(\"CBOW-5-NS-16k-2024-04-19_14-27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6ebd76f-ea44-4b6a-b12d-738223eaec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from trained_models\\CBOW-5-NS-16k-2024-04-19_14-27.pth\n"
     ]
    }
   ],
   "source": [
    "# Now - let's see what we can get from the embedding model for various word arithmetic tests\n",
    "embedding_model = \"CBOW-5-NS\"\n",
    "mymodel = CBOW_NegativeSampling(embed_dim=512, tokenizer=tokenizer)\n",
    "mymodel.load_weights(\"trained_models\\CBOW-5-NS-16k-2024-04-19_14-27.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b18a0e1f-7d60-400a-bfe4-84ff232020cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest tokens for: Pacific\n",
      "Token: [9854] - ['▁Pacific']\n",
      "------------------------------------------------------------\n",
      "Id: 1 - world\n",
      "Id: 2 - Atlantic\n",
      "Id: 3 - delights\n",
      "Id: 4 - assembled\n",
      "Id: 5 - Union\n",
      "Id: 6 - eastern\n",
      "Id: 7 - haste\n",
      "Id: 8 - ishment\n",
      "Id: 9 - emper\n",
      "Id: 10 - Government\n"
     ]
    }
   ],
   "source": [
    "def print_closest_ids(string):\n",
    "    tok = tokenizer.encode_as_ids(string)\n",
    "    tok_text = tokenizer.encode_as_pieces(string)\n",
    "    if len(tok)>1:\n",
    "        print(\"Try new token - token length > 1\")\n",
    "        return\n",
    "\n",
    "    token_embedding = mymodel.get_embedding(tok)\n",
    "    closest_ids = mymodel.find_closest_embeddings(token_embedding, n=11)\n",
    "    closest_ids = (closest_ids.to('cpu')).flatten().tolist()\n",
    "    print(f\"Closest tokens for: {string}\\nToken: {tok} - {tok_text}\\n{'-'*60}\")\n",
    "    for i, id in enumerate(closest_ids):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        print(f\"Id: {i} - {tokenizer.decode(id)}\")\n",
    "\n",
    "# Testing\n",
    "test_word = \"Pacific\"\n",
    "print_closest_ids(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1e5562be-4e97-483f-b139-7212a80beba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest tokens for: 'king' - 'man' + 'woman'\n",
      "------------------------------------------------------------\n",
      "Id: 0 - woman\n",
      "Id: 1 - king\n",
      "Id: 2 - Israel\n",
      "Id: 3 - son\n",
      "Id: 4 - LORD\n",
      "Id: 5 - unto\n",
      "Id: 6 - sons\n",
      "Id: 7 - thy\n",
      "Id: 8 - priest\n",
      "Id: 9 - her\n",
      "Id: 10 - thee\n"
     ]
    }
   ],
   "source": [
    "# Defining a - b + c = ?\n",
    "def closest_arith(a, b, c, n=11):\n",
    "    \n",
    "    tok_a = tokenizer.encode_as_ids(a)\n",
    "    tok_b = tokenizer.encode_as_ids(b)\n",
    "    tok_c = tokenizer.encode_as_ids(c)\n",
    "    \n",
    "    if (len(tok_a) + len(tok_b) + len(tok_c)) > 3:\n",
    "        print(\"Words not single tokens\")\n",
    "        return\n",
    "    \n",
    "    emb_a = mymodel.get_embedding(tok_a)\n",
    "    emb_b = mymodel.get_embedding(tok_b)\n",
    "    emb_c = mymodel.get_embedding(tok_c)\n",
    "\n",
    "    new_emb = (emb_a - emb_b + emb_c)\n",
    "    new_emb = new_emb / new_emb.norm()\n",
    "    closest_ids = mymodel.find_closest_embeddings(new_emb, n)\n",
    "    closest_ids = (closest_ids.to('cpu')).flatten().tolist()\n",
    "    print(f\"Closest tokens for: '{a}' - '{b}' + '{c}'\\n{'-'*60}\")\n",
    "    for i, id in enumerate(closest_ids):\n",
    "        print(f\"Id: {i} - {tokenizer.decode(id)}\")\n",
    "\n",
    "a = \"king\"\n",
    "b = \"man\"\n",
    "c = \"woman\"\n",
    "closest_arith(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "267d596c-daca-4257-a375-47789335c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical Linear Interp. for: 'huge' and 'big''\n",
      "------------------------------------------------------------\n",
      "Id: 0 - huge\n",
      "Id: 1 - ination\n",
      "Id: 2 - big\n",
      "Id: 3 - Amendment\n",
      "Id: 4 - like\n",
      "Id: 5 - ilitar\n",
      "Id: 6 - 35\n",
      "Id: 7 - meant\n",
      "Id: 8 - iki\n",
      "Id: 9 - sound\n",
      "Id: 10 - m\n"
     ]
    }
   ],
   "source": [
    "def slerp(val, low, high):\n",
    "    \"\"\"\n",
    "    Perform spherical interpolation between two vectors.\n",
    "\n",
    "    Args:\n",
    "        val (float): The interpolation parameter between 0 and 1, where 0 returns `low` and 1 returns `high`.\n",
    "        low (torch.Tensor): The starting vector of the interpolation.\n",
    "        high (torch.Tensor): The ending vector of the interpolation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The interpolated vector.\n",
    "    \"\"\"\n",
    "    low_norm = low / torch.norm(low)\n",
    "    high_norm = high / torch.norm(high)\n",
    "\n",
    "    omega = torch.acos((low_norm * high_norm).sum())\n",
    "\n",
    "    if torch.isnan(omega) or omega < 1e-6:\n",
    "        # If vectors are nearly parallel, use linear interpolation to avoid division by zero in sin(omega)\n",
    "        return (1 - val) * low + val * high\n",
    "\n",
    "    sin_omega = torch.sin(omega)\n",
    "    scale0 = torch.sin((1.0 - val) * omega) / sin_omega\n",
    "    scale1 = torch.sin(val * omega) / sin_omega\n",
    "\n",
    "    return scale0 * low + scale1 * high\n",
    "\n",
    "def get_slerp(a, b, n=11):\n",
    "    \n",
    "    tok_a = tokenizer.encode_as_ids(a)\n",
    "    tok_b = tokenizer.encode_as_ids(b)\n",
    "    if (len(tok_a) + len(tok_b)) > 3:\n",
    "        print(\"Words not single tokens\")\n",
    "        return\n",
    "    \n",
    "    emb_a = mymodel.get_embedding(tok_a)\n",
    "    emb_b = mymodel.get_embedding(tok_b)\n",
    "    \n",
    "    new_emb = slerp(0.1, emb_a, emb_b)\n",
    "    closest_ids = mymodel.find_closest_embeddings(new_emb, n)\n",
    "    closest_ids = (closest_ids.to('cpu')).flatten().tolist()\n",
    "    print(f\"Spherical Linear Interp. for: '{a}' and '{b}''\\n{'-'*60}\")\n",
    "    for i, id in enumerate(closest_ids):\n",
    "        print(f\"Id: {i} - {tokenizer.decode(id)}\")\n",
    "\n",
    "a = \"huge\"\n",
    "b = \"big\"\n",
    "get_slerp(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
