{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0948d168-bc6d-49f0-a0a8-46ffef674a9c",
   "metadata": {},
   "source": [
    "# Embedding Trainer\n",
    "---\n",
    "Main script to train our various embedding models. What we'll do is import our 'Embedding Model' objects that we'll define in other files - and this code will be the training loop and will save the results to various folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5d43-dfc7-4007-9d54-8527bbf69b22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create our Dataloader and Tokenizer\n",
    "---\n",
    "We already defined these and trained the tokenizer in the other files. So, let's go ahead and instantiate these as a first step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84fc05-e0dc-4820-b6d5-7593b3569bda",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce4ce0c-327e-4491-a5d2-97dae3584ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow for easy access of other packages in this directory, let's first nav to the project root\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49e9ebe-1710-4b4b-9828-c79e96dd34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.dataloader import MyDataLoader\n",
    "from tokenizer.tokenizer import MyTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18bf2d-67c0-4610-bee2-c956cb56b126",
   "metadata": {},
   "source": [
    "### Instantiate our Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b78d90c-3957-4114-90e7-8bf6a60c19c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars: 62911\n",
      "============================================================\n",
      "There are a vast number of absurd and mischievous fallacies, which pass readily in the world for sense and virtue, while in truth they tend only to fortify error and encourage crime. Mr. Bentham has enumerated the most conspicuous of these in the book before us.\n",
      "\n",
      "Whether it be necessary there should be a middleman between the cultivator and the possessor, learned economists have doubted; but neither gods, men, nor booksellers can doubt the necessity of a middleman between Mr. Bentham and the pub\n"
     ]
    }
   ],
   "source": [
    "dl = MyDataLoader(promptuser=False)    # By setting promptuser=False, we just use the 'enwiki_articles_20240320_mini' dataset (50MB)\n",
    "dataloader = dl.get_dataloader()\n",
    "\n",
    "for batch in dataloader:\n",
    "    sample_data = batch[0][0]\n",
    "    break\n",
    "\n",
    "print(f\"Number of chars: {len(sample_data)}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(sample_data[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d56a8-872e-45bc-93e6-cda4428f947a",
   "metadata": {},
   "source": [
    "### Instantiate our Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f352301-58ec-4c6a-ba92-101ea383444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689, 147, 5, 4474, 1122, 16, 7587, 21, 1716, 2509, 15815, 1226, 173, 164, 15941, 128, 564, 6311, 33, 6, 635, 65, 1771, 21, 3073, 15941, 1084, 33, 1710, 142, 3598, 454, 32, 2512, 1342, 6381, 21, 4281, 3426, 15944, 1416, 15944, 122, 2714, 90, 319, 49]\n",
      "------------------------------------------------------------\n",
      "['▁There', '▁are', '▁a', '▁vast', '▁number', '▁of', '▁absurd', '▁and', '▁mis', 'chie', 'vous', '▁fall', 'ac', 'ies', ',', '▁which', '▁pass', '▁readily', '▁in', '▁the', '▁world', '▁for', '▁sense', '▁and', '▁virtue', ',', '▁while', '▁in', '▁truth', '▁they', '▁tend', '▁only', '▁to', '▁fort', 'ify', '▁error', '▁and', '▁encourage', '▁crime', '.', '▁Mr', '.', '▁B', 'enth', 'am', '▁has', '▁e']\n",
      "------------------------------------------------------------\n",
      "There are a vast number of absurd and mischievous fallacies, which pass readily in the world for sense and virtue, while in truth they tend only to fortify error and encourage crime. Mr. Bentham has e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MyTokenizer()\n",
    "\n",
    "# Ensure our tokenizer is running properly\n",
    "chars_to_print = 200\n",
    "print(tokenizer.encode_as_ids(sample_data[:chars_to_print]))\n",
    "print(f\"{'-'*60}\")\n",
    "print(tokenizer.encode_as_pieces(sample_data[:chars_to_print]))\n",
    "print(f\"{'-'*60}\")\n",
    "print(tokenizer.decode(tokenizer.encode_as_ids(sample_data[:chars_to_print])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0484a7-8dbf-4e9f-a809-4f3936f30949",
   "metadata": {},
   "source": [
    "## Ensure Our Data Pipeline is Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5caaa-7fa2-4591-a07e-7d469f9c799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
