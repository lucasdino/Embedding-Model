{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bb7d46-f65f-47c0-84f1-0ea75770c48d",
   "metadata": {},
   "source": [
    "## Using the GPT-2 Tokenizer from Hugging Face\n",
    "---\n",
    "Goal is to be able to tokenize large amounts of text so that I can train a word embedding model on the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40d00f-ab0a-4fda-bc5f-3cd21607c060",
   "metadata": {},
   "source": [
    "### 1) Import GPT2Tokenizer\n",
    "---\n",
    "While we built a BPETokenizer in the other files, we'll take advantage of the GPT2Tokenizer because 1) It's better (better token representations); 2) Likely more optimized, though our encoding and decoding is pretty slick now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b226c5ac-1015-4ed3-b900-5f775718cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# First import GPT2Tokenizer from HuggingFace Transformers library\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321baeb6-c031-49ba-8df1-56dc0bbbdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e86975-13fc-4d0d-a766-d1076e6a57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: tensor([[7120, 6291, 2420, 2925,  994,   13]])\n",
      "Decoded: Your sample text goes here.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize sample text\n",
    "text = \"Your sample text goes here.\"\n",
    "encoded_input = tokenizer.encode(text, return_tensors='pt')\n",
    "decoded_output = tokenizer.decode(encoded_input[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Encoded: {encoded_input}\")\n",
    "print(f\"Decoded: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa94be-536c-405c-97c3-56fe64482889",
   "metadata": {},
   "source": [
    "### 2) Load in our data from Pytorch's existing datasets \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabfaea1-8502-485d-b0a2-5fb5b74f456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import pytorch and the Dataloader\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36b6585-27f8-4a6a-9ffd-07f779746553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a custom Dataset class to load in our dataset\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "class TextFileDataset(Dataset):\n",
    "    def __init__(self, directory, tokenizer, max_length=512):\n",
    "        self.file_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        encoded = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
    "        return encoded.input_ids.squeeze(0), encoded.attention_mask.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4cda363-9ec5-4939-9a9f-99ae5cb866d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our wiki8_dataset\n",
    "wiki8_dataset = TextFileDataset(directory=\"..\\\\data\\\\wikitext8_680MB\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e006e6c-2d9f-4562-9a1e-8274b523dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our dataloader. Note - batch_size refers to # of 25MB chunks each batch is\n",
    "wiki8_dataloader = DataLoader(wiki8_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5e89e0-364b-4bd2-97df-9cc34e80901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Text 1: er captain james cook capitancook was a free open content travel guide the website was a wikiwiki so everyone could create or edit articles in order to share travel experiences and independent information capitancook provided more than one eight zero zero articles and photos on destinations around the world all the articles and photos were published under the gnu free documentation license on november two nine two zero zero three capitancook merged with world six six wiki communities gfdl from the creater wshun zero two two zero two four dec two zero zero four utc the comic strip barnaby by crockett johnson best known today for his children s books such as harold and the purple crayon featured an almost cherubic looking five year old and his far from cherubic fairy godfather mr o malley a short cigar smoking man with four tiny wings barnaby got in a fair number of scrapes but most of them were either of mr o malley s making or resulted in embarrassment of some sort for the rather clumsy fairy godfather mr o malley is a member of the elves leprechauns gnomes and little men s chowder b one b two holt hardbacks and their reprints bb one bb six balantine books s sunday strip six zero six two one nine six zero six two version cr comics revue one nine four two one mr o mally q one b one bb one s six zero cr two blackout bb one three spies bb one four ogre q one bb one five psychologist q one b one bb one six zero cr six air raid warden b one bb one seven mcsnoyd q two b one bb one eight scrap drive q two b one bb one nine jane q two b one bb two six zero cr one zero gorgon q two b one bb two s six one cr one nine four three one one gus q three b one bb two s six one cr one two the hot coffee ring q three b one bb two six one cr one three quartet q three b two bb two one four garden b two bb two six one cr one five lion b two bb two six one cr one six giant b two bb two six one cr one seven gorgon s father b two bb two six one cr one eight kiddie camp bb two one nine o malley for congress b two bb three two zero investigating santa bb three one\n",
      "\n",
      "Batch 2:\n",
      "Text 1:  five five two zero zero three ending this year cisco kid one nine five zero one nine five six the honeymooners one nine five five one nine five six births january five julia hills actress january seven david caruso actor december two five susan king uk television presenter deaths december seven huntley gordon pioneer hollywood actor one nine five six years in television jeremy brett in the role of sherlock holmes peter jeremy william huggins november three one nine three three september one two one nine nine five better known as jeremy brett was a british actor brett was born in berkswell grange warwickshire england he was educated at eton college brett later claimed that he was an academic disaster at eton and attributed his learning difficulties to dyslexia however he excelled at singing and was a member of the choir while at eton jeremy brett trained as an actor at the central school of speech and drama in london he made his professional acting debut at the library theatre in manchester in one nine five four brett made his london stage debut with the old vic company in one nine five six he would go on to play many classical roles on stage including numerous shakespearean parts in his early career with the old vic and later with the royal national theatre brett made his first television appearance in one nine five four and his first feature film appearance in one nine five five in one nine five eight jeremy brett married the actress anna massey daughter of raymond massey but they divorced in one nine six two they had a son named david huggins born one nine five nine who is now a successful british novelist years later brett and massey appeared together in the bbc s dramatization of rebecca one nine seven eight with brett playing the haunted hero max de winter and massey playing the sinister housekeeper mrs danvers david huggins also played a bit part in the film in one nine seven six brett married american pbs producer joan wilson but she died of cancer in one nine eight five brett was devastated by wilson s untimely death and he never remarried roger delgado left and jeremy brett in an episode of the one nine six eight tv series the champions from the early one nine six zero s onwards brett was rarely absent from british television screens he starred in many classic ser\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (input_ids, attention_mask) in enumerate(wiki8_dataloader):\n",
    "    if i >= 2:  # Just look at the first 2 batches\n",
    "        break\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    for j in range(input_ids.size(0)):  # Loop through each item in the batch\n",
    "        decoded_text = tokenizer.decode(input_ids[j], skip_special_tokens=True)\n",
    "        print(f\"Text {j+1}: {decoded_text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
